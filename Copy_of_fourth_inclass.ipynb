{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of fourth_inclass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilnooney/nooneyakhil-spring2020/blob/master/Copy_of_fourth_inclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lysKUiaonR-s",
        "colab_type": "code",
        "outputId": "a6b60249-2708-4e48-e895-210d5c2f88fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "pip install pysbd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysbd\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/49/4799b3cdf80aee5fa4562a3929eda738845900bbeef4ee60481196ad4d1a/pysbd-0.2.3-py3-none-any.whl\n",
            "Installing collected packages: pysbd\n",
            "Successfully installed pysbd-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILXQqEewng55",
        "colab_type": "code",
        "outputId": "ded7a2f7-998a-452f-92f3-964c615ccabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 1.1.1 Number of sentences \n",
        "d = open(\"/content/01-05-1  Adams v Tanner.txt\", \"r\")\n",
        "f = d.read()\n",
        "import pysbd\n",
        "seg = pysbd.Segmenter(language =\"en\", clean = False)\n",
        "segmentedlist  = seg.segment(f)\n",
        "num = len(segmentedlist)\n",
        "print(\"Total number of sentences in the given text file:-\", num)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of sentences in the given text file:- 220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-E3iTBXnnu3",
        "colab_type": "code",
        "outputId": "bb7e028b-5c3a-4f1c-fb6a-fb3973cf1b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#1.1.2 Number of words\n",
        "from collections import Counter\n",
        "#word_list = f.split()\n",
        "words = f.split()\n",
        "print('Number of words in text file :', len(words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in text file : 3707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtXaJii_sU9A",
        "colab_type": "code",
        "outputId": "54828869-34f3-4a3d-8ed1-cdda3ab681fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1.1.3 Number of characters \n",
        "number_of_characters = len(f)\n",
        "print(\"Number of characters in the Text file:-\", number_of_characters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of characters in the Text file:- 20453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p2FW4Gcwfno",
        "colab_type": "code",
        "outputId": "0d1450f4-32a9-404b-c225-291b89f812df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1.1.4 Average word length ---- Method 1\n",
        "d = open(\"file.txt\", \"r\", encoding='cp1252')\n",
        "total_wordcount_sum = 0\n",
        "total_wordlength_sum = 0\n",
        "for line in d:\n",
        "    word_1 = line.split()\n",
        "    # sum up the word counts\n",
        "    total_wordcount_sum += len(word_1)\n",
        "    for w in word_1:\n",
        "        # sum up the word lengths\n",
        "        total_wordlength_sum += len(w)\n",
        "# invoke floating point division for Python versions < 3.0\n",
        "total_wordlength_average = total_wordlength_sum/float(total_wordcount_sum)\n",
        "print(\"Average word length:- \", total_wordlength_average)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average word length:-  4.510385756676558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWdTFm9axg-7",
        "colab_type": "code",
        "outputId": "4eea4a8c-3498-4361-9b9d-9f9846e9eaca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1.1.4 Average word length ---- Method 2\n",
        "with  open(\"file.txt\", \"r\", encoding='cp1252') as f:\n",
        "  w = [len(word) for line in f for word in line.rstrip().split(\" \")]\n",
        "  w_avg = sum(w)/len(w)\n",
        "  print(\"Average word length:- \", w_avg)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average word length:-  4.478971336726493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymPo7t4l3EWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install stop-words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lxEiHnI73zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGZkgZoS1IWE",
        "colab_type": "code",
        "outputId": "eebb17b3-54ea-480d-d682-6eabc9f76d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zSvQwjcNCUH",
        "colab_type": "code",
        "outputId": "1062582c-c0a5-4900-a86e-5996d12c3226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#1.1.5 Number of stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "import pandas as pd\n",
        "lists=[]\n",
        "incrementer=0\n",
        "stop_words=stopwords.words(\"english\")\n",
        "b=[a for a in segmentedlist]\n",
        "df=pd.DataFrame(b,columns=['text_data'])\n",
        "for temp in df['text_data']:\n",
        "  tokens=word_tokenize(temp)\n",
        "  for y in tokens:\n",
        "    if y in stop_words:\n",
        "      incrementer=incrementer+1\n",
        "print('Stop Words Count',incrementer)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stop Words Count 1734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwP0JUtMC1mm",
        "colab_type": "code",
        "outputId": "83e04795-a905-46c6-e471-c276b68afe01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1.1.6 Number of Special Characters \n",
        "\n",
        "special_char = 0\n",
        "for line in f:\n",
        "  special_char += sum(not x.isalnum() for x in line)\n",
        "print(\"Total number of special characters in the file:=\", special_char)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of special characters in the file:= 4550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PSwdKEUISCn",
        "colab_type": "code",
        "outputId": "fc61c290-39ae-49cc-b908-29383665d913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1.1.7 Number of numerics\n",
        "\n",
        "value = [ i for i in f]\n",
        "numerics = len(list(filter(lambda x: x.isdigit(), value)))\n",
        "print(\"The Number of numerics:-\", numerics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Number of numerics:- 356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYDZKRqDDSk3",
        "colab_type": "code",
        "outputId": "38db03a3-3e97-44f8-b25c-e7eb2451c312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1.1.8 Number of uppercase words. Method-1\n",
        "\n",
        "uppercase_words = len(list(filter(lambda x: x.isupper(), value)))\n",
        "print(\"The Number of uppercase words:-\", uppercase_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Number of uppercase words:- 695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Osft5sQEhqy",
        "colab_type": "code",
        "outputId": "fcdfe9ae-837b-4e13-feda-77656f7113b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#1.1.8 Number of uppercase words. Method-2\n",
        "d = open(\"file.txt\", \"r\", encoding='cp1252')\n",
        "f = d.read()\n",
        "uppercase_words = 0\n",
        "uppercase =['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
        "for character in f:\n",
        "  if character in uppercase:\n",
        "    uppercase_words += 1\n",
        "print('The Number of uppercase words is:-',uppercase_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Number of uppercase words is:- 695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9IZD7mzHgin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1.2.1 Lower casing all the data\n",
        "\n",
        "with open(\"file.txt\", \"r\", encoding='cp1252') as f:\n",
        "   for line in f:\n",
        "       line = line.lower()\n",
        "       print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkpQMvCzbozM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1.2.2  Punctuation removal for all the data \n",
        "import re\n",
        "string = open(\"file.txt\", \"r\", encoding='cp1252').read() # open the input text file and read\n",
        "no_specials_string = re.sub('[!#?,.:\";]', '', string) # remove the Punctuation\n",
        "print(no_specials_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibvXKvN8e1V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1.2.3 \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyjB7U48vz4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}